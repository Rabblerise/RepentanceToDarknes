{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b27a697-4cf7-4ba8-899c-189ddacb2d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from collections import Counter\n",
    "import onnxruntime as ort\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8f21dcb-d1ec-485a-b3b7-e9beaf6db621",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatDataset(Dataset):\n",
    "    def __init__(self, input_sequences, target_sequences, response_types):\n",
    "        self.input_sequences = input_sequences\n",
    "        self.target_sequences = target_sequences\n",
    "        self.response_types = response_types\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.input_sequences[idx], self.target_sequences[idx], self.response_types[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bebbea13-ae0f-443d-a254-14499948928f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(texts, tokenizer, max_length):\n",
    "    return [torch.tensor(tokenizer(text), dtype=torch.long) for text in texts]\n",
    "\n",
    "def pad_collate_fn(batch):\n",
    "    input_seqs, target_seqs, response_types = zip(*batch)\n",
    "    input_seqs_padded = pad_sequence(input_seqs, batch_first=True, padding_value=0)\n",
    "    target_seqs_padded = pad_sequence(target_seqs, batch_first=True, padding_value=0)\n",
    "    response_types = torch.tensor(response_types, dtype=torch.long)\n",
    "    return input_seqs_padded, target_seqs_padded, response_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81d7cebc-1208-46ba-a896-0f5026d865a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка и обработка данных\n",
    "data = pd.read_csv('chaos_god_dataset.csv')\n",
    "data['Bot_Response'] = data['Bot_Response'].apply(lambda x: '<start> ' + x + ' <end>')\n",
    "\n",
    "all_texts = data['User_Message'].tolist() + data['Bot_Response'].tolist()\n",
    "tokenizer = Counter(' '.join(all_texts).split())\n",
    "vocab = {word: idx + 1 for idx, (word, _) in enumerate(tokenizer.items())}\n",
    "vocab_size = len(vocab) + 1\n",
    "\n",
    "def encode(text, vocab):\n",
    "    return [vocab[word] for word in text.split() if word in vocab]\n",
    "\n",
    "input_sequences = tokenize(data['User_Message'].tolist(), lambda x: encode(x, vocab), max_length=None)\n",
    "target_sequences = tokenize(data['Bot_Response'].tolist(), lambda x: encode(x, vocab), max_length=None)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "response_labels_encoded = label_encoder.fit_transform(data['Response_Type'])\n",
    "\n",
    "X_train, X_test, y_train, y_test, train_resp, test_resp = train_test_split(input_sequences, target_sequences, response_labels_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = ChatDataset(X_train, y_train, train_resp)\n",
    "test_dataset = ChatDataset(X_test, y_test, test_resp)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, collate_fn=pad_collate_fn, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, collate_fn=pad_collate_fn, shuffle=False)\n",
    "\n",
    "max_seq_length = max(max(len(seq) for seq in input_sequences), max(len(seq) for seq in target_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52c8753e-0d5c-47fc-adb8-a6d5c0ab5758",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.encoder_lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.decoder_lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, src, trg, hidden, cell, use_teacher_forcing):\n",
    "        batch_size = src.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "        trg_vocab_size = self.fc.out_features\n",
    "\n",
    "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(src.device)\n",
    "        embedded_src = self.embedding(src)\n",
    "        encoder_outputs, (hidden, cell) = self.encoder_lstm(embedded_src, (hidden, cell))\n",
    "\n",
    "        input = trg[:, 0]\n",
    "        for t in range(1, trg_len):\n",
    "            input = input.unsqueeze(1)\n",
    "            embedded_input = self.embedding(input)\n",
    "            decoder_output, (hidden, cell) = self.decoder_lstm(embedded_input, (hidden, cell))\n",
    "            output = self.fc(decoder_output.squeeze(1))\n",
    "            outputs[:, t, :] = output\n",
    "\n",
    "            if use_teacher_forcing:\n",
    "                input = trg[:, t]\n",
    "            else:\n",
    "                input = output.argmax(1)\n",
    "\n",
    "        return outputs, hidden, cell\n",
    "\n",
    "class ResponseClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, num_classes):\n",
    "        super(ResponseClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.fc1 = nn.Linear(embedding_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x).mean(dim=1)\n",
    "        x = torch.relu(self.fc1(embedded))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f714a7f3-8897-45f4-a08d-44c89e8893bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80, Loss Seq2Seq: 6.77866268157959, Loss Classifier: 1.793488621711731\n",
      "Epoch 2/80, Loss Seq2Seq: 6.278234958648682, Loss Classifier: 1.4843406677246094\n",
      "Epoch 3/80, Loss Seq2Seq: 5.521275520324707, Loss Classifier: 1.4282360076904297\n",
      "Epoch 4/80, Loss Seq2Seq: 5.236615180969238, Loss Classifier: 1.384177803993225\n",
      "Epoch 5/80, Loss Seq2Seq: 5.177277088165283, Loss Classifier: 1.4297065734863281\n",
      "Epoch 6/80, Loss Seq2Seq: 5.410035610198975, Loss Classifier: 1.0753049850463867\n",
      "Epoch 7/80, Loss Seq2Seq: 5.597518444061279, Loss Classifier: 1.018714189529419\n",
      "Epoch 8/80, Loss Seq2Seq: 4.2173004150390625, Loss Classifier: 1.3303660154342651\n",
      "Epoch 9/80, Loss Seq2Seq: 4.36333703994751, Loss Classifier: 0.8859329223632812\n",
      "Epoch 10/80, Loss Seq2Seq: 4.5608320236206055, Loss Classifier: 1.2981430292129517\n",
      "Epoch 11/80, Loss Seq2Seq: 4.190622806549072, Loss Classifier: 0.9888630509376526\n",
      "Epoch 12/80, Loss Seq2Seq: 4.9105987548828125, Loss Classifier: 1.038123607635498\n",
      "Epoch 13/80, Loss Seq2Seq: 4.8461809158325195, Loss Classifier: 0.6770135164260864\n",
      "Epoch 14/80, Loss Seq2Seq: 5.12318229675293, Loss Classifier: 0.8556033968925476\n",
      "Epoch 15/80, Loss Seq2Seq: 4.929763317108154, Loss Classifier: 0.765141487121582\n",
      "Epoch 16/80, Loss Seq2Seq: 4.023346424102783, Loss Classifier: 0.64002925157547\n",
      "Epoch 17/80, Loss Seq2Seq: 4.504642486572266, Loss Classifier: 0.6050741076469421\n",
      "Epoch 18/80, Loss Seq2Seq: 3.405571460723877, Loss Classifier: 0.8001407980918884\n",
      "Epoch 19/80, Loss Seq2Seq: 3.466567277908325, Loss Classifier: 0.9960057139396667\n",
      "Epoch 20/80, Loss Seq2Seq: 4.817073822021484, Loss Classifier: 0.515367329120636\n",
      "Epoch 21/80, Loss Seq2Seq: 4.512210845947266, Loss Classifier: 0.5399962067604065\n",
      "Epoch 22/80, Loss Seq2Seq: 3.165592670440674, Loss Classifier: 0.5661217570304871\n",
      "Epoch 23/80, Loss Seq2Seq: 4.70018196105957, Loss Classifier: 0.6728292107582092\n",
      "Epoch 24/80, Loss Seq2Seq: 4.25111198425293, Loss Classifier: 0.5275119543075562\n",
      "Epoch 25/80, Loss Seq2Seq: 4.34423303604126, Loss Classifier: 0.48784342408180237\n",
      "Epoch 26/80, Loss Seq2Seq: 2.6786370277404785, Loss Classifier: 0.4942674934864044\n",
      "Epoch 27/80, Loss Seq2Seq: 2.772789239883423, Loss Classifier: 0.5769057869911194\n",
      "Epoch 28/80, Loss Seq2Seq: 4.225962162017822, Loss Classifier: 0.5918321013450623\n",
      "Epoch 29/80, Loss Seq2Seq: 2.357495069503784, Loss Classifier: 0.31657853722572327\n",
      "Epoch 30/80, Loss Seq2Seq: 2.5964150428771973, Loss Classifier: 0.5137938261032104\n",
      "Epoch 31/80, Loss Seq2Seq: 2.179983615875244, Loss Classifier: 0.3741655945777893\n",
      "Epoch 32/80, Loss Seq2Seq: 3.7408506870269775, Loss Classifier: 0.3953641355037689\n",
      "Epoch 33/80, Loss Seq2Seq: 2.182265281677246, Loss Classifier: 0.22839106619358063\n",
      "Epoch 34/80, Loss Seq2Seq: 1.9838870763778687, Loss Classifier: 0.22063811123371124\n",
      "Epoch 35/80, Loss Seq2Seq: 3.2146503925323486, Loss Classifier: 0.4123959541320801\n",
      "Epoch 36/80, Loss Seq2Seq: 3.4075775146484375, Loss Classifier: 0.18055902421474457\n",
      "Epoch 37/80, Loss Seq2Seq: 1.7786904573440552, Loss Classifier: 0.2076248973608017\n",
      "Epoch 38/80, Loss Seq2Seq: 3.486180067062378, Loss Classifier: 0.32186588644981384\n",
      "Epoch 39/80, Loss Seq2Seq: 1.855818510055542, Loss Classifier: 0.5045920610427856\n",
      "Epoch 40/80, Loss Seq2Seq: 1.6796894073486328, Loss Classifier: 0.14990226924419403\n",
      "Epoch 41/80, Loss Seq2Seq: 2.7413463592529297, Loss Classifier: 0.1794349104166031\n",
      "Epoch 42/80, Loss Seq2Seq: 3.383991003036499, Loss Classifier: 0.21407175064086914\n",
      "Epoch 43/80, Loss Seq2Seq: 1.5546077489852905, Loss Classifier: 0.33467960357666016\n",
      "Epoch 44/80, Loss Seq2Seq: 2.7865402698516846, Loss Classifier: 0.28095772862434387\n",
      "Epoch 45/80, Loss Seq2Seq: 1.452636480331421, Loss Classifier: 0.14839904010295868\n",
      "Epoch 46/80, Loss Seq2Seq: 2.4680519104003906, Loss Classifier: 0.08901392668485641\n",
      "Epoch 47/80, Loss Seq2Seq: 1.2728825807571411, Loss Classifier: 0.3062860369682312\n",
      "Epoch 48/80, Loss Seq2Seq: 1.2858175039291382, Loss Classifier: 0.1808386594057083\n",
      "Epoch 49/80, Loss Seq2Seq: 2.382232427597046, Loss Classifier: 0.5290724039077759\n",
      "Epoch 50/80, Loss Seq2Seq: 2.195904493331909, Loss Classifier: 0.0820629745721817\n",
      "Epoch 51/80, Loss Seq2Seq: 1.1559947729110718, Loss Classifier: 0.17436596751213074\n",
      "Epoch 52/80, Loss Seq2Seq: 1.1946502923965454, Loss Classifier: 0.22156819701194763\n",
      "Epoch 53/80, Loss Seq2Seq: 2.372654914855957, Loss Classifier: 0.23658999800682068\n",
      "Epoch 54/80, Loss Seq2Seq: 1.2037794589996338, Loss Classifier: 0.22326135635375977\n",
      "Epoch 55/80, Loss Seq2Seq: 1.4573818445205688, Loss Classifier: 0.26699817180633545\n",
      "Epoch 56/80, Loss Seq2Seq: 1.0615694522857666, Loss Classifier: 0.1997825652360916\n",
      "Epoch 57/80, Loss Seq2Seq: 1.7356443405151367, Loss Classifier: 0.09419554471969604\n",
      "Epoch 58/80, Loss Seq2Seq: 1.3256949186325073, Loss Classifier: 0.1991601437330246\n",
      "Epoch 59/80, Loss Seq2Seq: 1.049006462097168, Loss Classifier: 0.1290777027606964\n",
      "Epoch 60/80, Loss Seq2Seq: 1.0451782941818237, Loss Classifier: 0.13945810496807098\n",
      "Epoch 61/80, Loss Seq2Seq: 1.56625235080719, Loss Classifier: 0.2028893381357193\n",
      "Epoch 62/80, Loss Seq2Seq: 0.9561734199523926, Loss Classifier: 0.1442716270685196\n",
      "Epoch 63/80, Loss Seq2Seq: 1.4836539030075073, Loss Classifier: 0.13591156899929047\n",
      "Epoch 64/80, Loss Seq2Seq: 0.9614259004592896, Loss Classifier: 0.09195391088724136\n",
      "Epoch 65/80, Loss Seq2Seq: 0.9170082807540894, Loss Classifier: 0.11306881159543991\n",
      "Epoch 66/80, Loss Seq2Seq: 1.2718325853347778, Loss Classifier: 0.21434853971004486\n",
      "Epoch 67/80, Loss Seq2Seq: 0.8828575611114502, Loss Classifier: 0.018303144723176956\n",
      "Epoch 68/80, Loss Seq2Seq: 0.9109756946563721, Loss Classifier: 0.20090194046497345\n",
      "Epoch 69/80, Loss Seq2Seq: 1.1837323904037476, Loss Classifier: 0.34959301352500916\n",
      "Epoch 70/80, Loss Seq2Seq: 1.5021708011627197, Loss Classifier: 0.24039866030216217\n",
      "Epoch 71/80, Loss Seq2Seq: 1.1303104162216187, Loss Classifier: 0.2556142508983612\n",
      "Epoch 72/80, Loss Seq2Seq: 0.8758187294006348, Loss Classifier: 0.07131922990083694\n",
      "Epoch 73/80, Loss Seq2Seq: 1.0343515872955322, Loss Classifier: 0.0969483032822609\n",
      "Epoch 74/80, Loss Seq2Seq: 0.7932441234588623, Loss Classifier: 0.13166914880275726\n",
      "Epoch 75/80, Loss Seq2Seq: 1.1283042430877686, Loss Classifier: 0.0818425789475441\n",
      "Epoch 76/80, Loss Seq2Seq: 0.7924569845199585, Loss Classifier: 0.15371309220790863\n",
      "Epoch 77/80, Loss Seq2Seq: 0.8861511945724487, Loss Classifier: 0.104594387114048\n",
      "Epoch 78/80, Loss Seq2Seq: 0.7788974046707153, Loss Classifier: 0.19690844416618347\n",
      "Epoch 79/80, Loss Seq2Seq: 0.7635489702224731, Loss Classifier: 0.06830214709043503\n",
      "Epoch 80/80, Loss Seq2Seq: 0.7608336806297302, Loss Classifier: 0.15594735741615295\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "embedding_dim = 256\n",
    "hidden_dim = 512\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "seq2seq_model = Seq2Seq(vocab_size, embedding_dim, hidden_dim).to(device)\n",
    "classifier_model = ResponseClassifier(vocab_size, embedding_dim, num_classes).to(device)\n",
    "\n",
    "criterion_seq2seq = nn.CrossEntropyLoss(ignore_index=0)\n",
    "criterion_classifier = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_seq2seq = optim.Adam(seq2seq_model.parameters(), lr=0.001)\n",
    "optimizer_classifier = optim.Adam(classifier_model.parameters(), lr=0.001)\n",
    "\n",
    "def train_model(seq2seq_model, classifier_model, train_loader, criterion_seq2seq, criterion_classifier, optimizer_seq2seq, optimizer_classifier, epochs=10, teacher_forcing_ratio=0.5):\n",
    "    seq2seq_model.train()\n",
    "    classifier_model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for input_seqs, target_seqs, response_types in train_loader:\n",
    "            input_seqs, target_seqs, response_types = input_seqs.to(device), target_seqs.to(device), response_types.to(device)\n",
    "\n",
    "            # Инициализация скрытых состояний и состояний ячеек нулями\n",
    "            hidden = torch.zeros(1, input_seqs.size(0), hidden_dim).to(device)\n",
    "            cell = torch.zeros(1, input_seqs.size(0), hidden_dim).to(device)\n",
    "            \n",
    "            # Определение использования принуждения учителя\n",
    "            use_teacher_forcing = torch.tensor([1 if torch.rand(1).item() < teacher_forcing_ratio else 0]).to(device)\n",
    "            \n",
    "            # Seq2Seq модель\n",
    "            optimizer_seq2seq.zero_grad()\n",
    "            output_seq2seq, hidden, cell = seq2seq_model(input_seqs, target_seqs, hidden, cell, use_teacher_forcing)\n",
    "            loss_seq2seq = criterion_seq2seq(output_seq2seq.view(-1, vocab_size), target_seqs.view(-1))\n",
    "            loss_seq2seq.backward()\n",
    "            optimizer_seq2seq.step()\n",
    "\n",
    "            # Классификационная модель\n",
    "            optimizer_classifier.zero_grad()\n",
    "            output_classifier = classifier_model(input_seqs)\n",
    "            loss_classifier = criterion_classifier(output_classifier, response_types)\n",
    "            loss_classifier.backward()\n",
    "            optimizer_classifier.step()\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss Seq2Seq: {loss_seq2seq.item()}, Loss Classifier: {loss_classifier.item()}')\n",
    "\n",
    "train_model(seq2seq_model, classifier_model, train_loader, criterion_seq2seq, criterion_classifier, optimizer_seq2seq, optimizer_classifier, epochs=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ab1cdd6-4326-45d3-b572-8568f6995298",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13764\\4005210431.py:26: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if use_teacher_forcing:\n",
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\onnx\\symbolic_opset9.py:4476: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Экспорт моделей\n",
    "src_dummy_input = torch.randint(0, vocab_size, (1, max_seq_length)).long().to(device)\n",
    "trg_dummy_input = torch.randint(0, vocab_size, (1, max_seq_length)).long().to(device)\n",
    "hidden_dummy_input = torch.zeros(1, 1, hidden_dim).to(device)\n",
    "cell_dummy_input = torch.zeros(1, 1, hidden_dim).to(device)\n",
    "teacher_forcing_dummy_input = torch.tensor([1]).to(device)  # 1 для использования teacher forcing, 0 для его отключения\n",
    "\n",
    "# Экспорт модели Seq2Seq\n",
    "torch.onnx.export(\n",
    "    seq2seq_model, \n",
    "    (src_dummy_input, trg_dummy_input, hidden_dummy_input, cell_dummy_input, teacher_forcing_dummy_input),\n",
    "    \"seq2seq_model.onnx\",\n",
    "    input_names=[\"src\", \"trg\", \"hidden\", \"cell\", \"use_teacher_forcing\"],\n",
    "    output_names=[\"output\", \"hidden_out\", \"cell_out\"],\n",
    "    dynamic_axes={\"src\": {0: \"batch_size\", 1: \"sequence\"}, \"trg\": {0: \"batch_size\", 1: \"sequence\"}, \"output\": {0: \"batch_size\", 1: \"sequence\"}}\n",
    ")\n",
    "\n",
    "# Экспорт модели классификатора\n",
    "classifier_dummy_input = torch.randint(0, vocab_size, (1, max_seq_length)).long().to(device)\n",
    "torch.onnx.export(\n",
    "    classifier_model, \n",
    "    classifier_dummy_input, \n",
    "    \"classifier_model.onnx\", \n",
    "    input_names=[\"input\"], \n",
    "    output_names=[\"output\"], \n",
    "    dynamic_axes={\"input\": {0: \"batch_size\", 1: \"sequence\"}, \"output\": {0: \"batch_size\"}}\n",
    ")\n",
    "# Сохранение словаря vocab в JSON файл\n",
    "with open(\"vocab.json\", \"w\") as f:\n",
    "    json.dump(vocab, f)\n",
    "\n",
    "# Сохранение энкодера label_encoder в JSON файл\n",
    "with open(\"label_encoder.json\", \"w\") as f:\n",
    "    json.dump(label_encoder.classes_.tolist(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56ade771-1283-486a-b07e-61a06bfc9d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(seq2seq_model, classifier_model, input_seq, vocab, max_length):\n",
    "    input_seq = torch.tensor(encode(input_seq, vocab)).unsqueeze(0).long().to(device)\n",
    "    if input_seq.size(1) == 0:  # Если вопроса нет в словаре\n",
    "        return \"Не могу понять вопрос.\", \"Неизвестно\"\n",
    "    \n",
    "    seq2seq_model.eval()\n",
    "    classifier_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        embedded = seq2seq_model.embedding(input_seq)\n",
    "        encoder_outputs, (hidden, cell) = seq2seq_model.encoder_lstm(embedded)\n",
    "\n",
    "        target_seq = torch.tensor([vocab.get('<start>', 0)]).unsqueeze(0).long().to(device)\n",
    "        decoded_sentence = ''\n",
    "        for _ in range(max_length):\n",
    "            embedded = seq2seq_model.embedding(target_seq)\n",
    "            decoder_output, (hidden, cell) = seq2seq_model.decoder_lstm(embedded, (hidden, cell))\n",
    "            output = seq2seq_model.fc(decoder_output.squeeze(1))\n",
    "            top1 = output.argmax(1).item()\n",
    "            if top1 == vocab.get('<end>', 0):\n",
    "                break\n",
    "            decoded_sentence += ' ' + [key for key, value in vocab.items() if value == top1][0]\n",
    "            target_seq = torch.tensor([top1]).unsqueeze(0).long().to(device)\n",
    "\n",
    "        response_type = classifier_model(input_seq).argmax(1).item()\n",
    "        response_label = label_encoder.inverse_transform([response_type])[0]\n",
    "\n",
    "    return decoded_sentence.strip(), response_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c5471a3-cafc-4ad6-8e9f-2f06ce2db8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Вы:  Привет\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ответ бота: Ну что ты хочешь обсудить?\n",
      "Характер ответа: грубость\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Вы:  Как тебя зовут?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ответ бота: О, это не для\n",
      "Характер ответа: оскорбительный\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Вы:  Кто ты такой?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ответ бота: Мне без разницы.\n",
      "Характер ответа: оскорбительный\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Вы:  Ты веришь в существование души?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ответ бота: Душа? Она существует только в их собственных воображениях.\n",
      "Характер ответа: ироничный\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Вы:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "До свидания!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"Вы: \")\n",
    "    if user_input.lower() == '':\n",
    "        print(\"До свидания!\")\n",
    "        break\n",
    "    else:\n",
    "        decoded_sentence, response_type = decode_sequence(seq2seq_model, classifier_model, user_input, vocab, max_length=max_seq_length)\n",
    "        print(\"Ответ бота:\", decoded_sentence)\n",
    "        print(\"Характер ответа:\", response_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ae2d4d-9ac4-438d-b4a1-ed364b8a759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "# Загрузка модели\n",
    "ort_session = ort.InferenceSession(\"seq2seq_model.onnx\")\n",
    "\n",
    "# Подготовка входных данных\n",
    "src_dummy_input = torch.randint(0, vocab_size, (1, max_seq_length)).long().numpy()\n",
    "trg_dummy_input = torch.randint(0, vocab_size, (1, max_seq_length)).long().numpy()\n",
    "hidden_dummy_input = torch.zeros(1, 1, hidden_dim).numpy()\n",
    "cell_dummy_input = torch.zeros(1, 1, hidden_dim).numpy()\n",
    "\n",
    "# Выполнение инференса\n",
    "outputs = ort_session.run(\n",
    "    None,\n",
    "    {\n",
    "        \"src\": src_dummy_input,\n",
    "        \"trg\": trg_dummy_input,\n",
    "        \"hidden\": hidden_dummy_input,\n",
    "        \"cell\": cell_dummy_input\n",
    "    },\n",
    ")\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721826a6-ee2b-4eb2-b0c7-d2136a3f9297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка модели\n",
    "ort_session = ort.InferenceSession(\"classifier_model.onnx\")\n",
    "\n",
    "# Подготовка входных данных\n",
    "classifier_dummy_input = torch.randint(0, vocab_size, (1, max_seq_length)).long().numpy()\n",
    "\n",
    "# Выполнение инференса\n",
    "outputs = ort_session.run(\n",
    "    None,\n",
    "    {\n",
    "        \"input\": classifier_dummy_input\n",
    "    },\n",
    ")\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83d0592-dd3f-4ac4-8280-57c4e5a4be73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6311892c-5721-4dc1-b7d3-8d25deed029a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ff6a78-f578-489a-8184-2eddb845f3ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
